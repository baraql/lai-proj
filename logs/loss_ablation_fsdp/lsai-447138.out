START TIME: Sun May 18 17:39:53 CEST 2025
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
2025-05-18 17:40:14,311 - root - INFO - Setting seed to 42
2025-05-18 17:40:14,311 - root - INFO - Setting seed to 42
2025-05-18 17:40:14,311 - root - INFO - Setting seed to 42
2025-05-18 17:40:14,311 - root - INFO - Setting seed to 42
2025-05-18 17:40:14,311 - root - INFO - Experiment args: Namespace(dataset='/capstor/store/cscs/ethz/large-sc/datasets/train_data.parquet', tokenizer_name_or_path='unsloth/Mistral-Nemo-Base-2407-bnb-4bit', sequence_length=4096, batch_size=1, fused_optimizer=False, learning_rate=5e-05, lr_warmup_steps=100, training_steps=100, logging_frequency=5, profile=False, profile_step_start=10, profile_step_end=12, grad_max_norm=1, model_dtype='bf16', compile=False, scale=1, set_seed=42)
2025-05-18 17:40:19,842 - root - INFO - [rank 0] world size: 4
2025-05-18 17:40:19,842 - root - INFO - Setting up DataLoaders...
2025-05-18 17:40:21,988 - root - INFO - Setting up Model...
Total params: 8053329920
2025-05-18 17:40:55,875 - root - INFO - [rank 3] model is now: FullyShardedDataParallel
2025-05-18 17:40:55,875 - root - INFO - [rank 3] local params: 2013332480
Total params: 8053329920
2025-05-18 17:40:56,016 - root - INFO - [rank 2] model is now: FullyShardedDataParallel
2025-05-18 17:40:56,017 - root - INFO - [rank 2] local params: 2013332480
Total params: 8053329920
2025-05-18 17:40:56,332 - root - INFO - [rank 0] model is now: FullyShardedDataParallel
2025-05-18 17:40:56,333 - root - INFO - [rank 0] local params: 2013332480
2025-05-18 17:40:56,334 - root - INFO - Starting training!
Total params: 8053329920
2025-05-18 17:40:58,384 - root - INFO - [rank 1] model is now: FullyShardedDataParallel
2025-05-18 17:40:58,384 - root - INFO - [rank 1] local params: 2013332480
2025-05-18 17:41:04,546 - root - INFO - Step: 1 | Loss: 11.91 | Tokens per second: 499.28 | Training tokens per second (%): 19.38 | MFU (%): 0.94 | TFLOPs: 9.25
2025-05-18 17:41:06,791 - root - INFO - Step: 5 | Loss: 11.92 | Tokens per second: 7366.50 | Training tokens per second (%): 11.41 | MFU (%): 13.80 | TFLOPs: 136.45
2025-05-18 17:41:09,654 - root - INFO - Step: 10 | Loss: 11.89 | Tokens per second: 7206.26 | Training tokens per second (%): 25.72 | MFU (%): 13.50 | TFLOPs: 133.48
2025-05-18 17:41:12,558 - root - INFO - Step: 15 | Loss: 11.67 | Tokens per second: 7103.60 | Training tokens per second (%): 35.21 | MFU (%): 13.30 | TFLOPs: 131.58
2025-05-18 17:41:15,455 - root - INFO - Step: 20 | Loss: 11.32 | Tokens per second: 7121.49 | Training tokens per second (%): 34.78 | MFU (%): 13.34 | TFLOPs: 131.91
2025-05-18 17:41:18,297 - root - INFO - Step: 25 | Loss: 10.83 | Tokens per second: 7259.46 | Training tokens per second (%): 18.28 | MFU (%): 13.60 | TFLOPs: 134.46
2025-05-18 17:41:21,180 - root - INFO - Step: 30 | Loss: 9.78 | Tokens per second: 7155.59 | Training tokens per second (%): 26.99 | MFU (%): 13.40 | TFLOPs: 132.54
2025-05-18 17:41:24,087 - root - INFO - Step: 35 | Loss: 9.88 | Tokens per second: 7096.81 | Training tokens per second (%): 13.78 | MFU (%): 13.29 | TFLOPs: 131.45
2025-05-18 17:41:26,897 - root - INFO - Step: 40 | Loss: 9.85 | Tokens per second: 7342.49 | Training tokens per second (%): 9.95 | MFU (%): 13.75 | TFLOPs: 136.00
2025-05-18 17:41:29,727 - root - INFO - Step: 45 | Loss: 9.35 | Tokens per second: 7291.68 | Training tokens per second (%): 15.59 | MFU (%): 13.66 | TFLOPs: 135.06
2025-05-18 17:41:32,535 - root - INFO - Step: 50 | Loss: 9.22 | Tokens per second: 7346.08 | Training tokens per second (%): 10.93 | MFU (%): 13.76 | TFLOPs: 136.07
2025-05-18 17:41:35,422 - root - INFO - Step: 55 | Loss: 9.34 | Tokens per second: 7146.38 | Training tokens per second (%): 28.32 | MFU (%): 13.38 | TFLOPs: 132.37
2025-05-18 17:41:38,302 - root - INFO - Step: 60 | Loss: 8.70 | Tokens per second: 7164.24 | Training tokens per second (%): 26.71 | MFU (%): 13.42 | TFLOPs: 132.70
2025-05-18 17:41:41,173 - root - INFO - Step: 65 | Loss: 8.95 | Tokens per second: 7185.32 | Training tokens per second (%): 24.18 | MFU (%): 13.46 | TFLOPs: 133.09
2025-05-18 17:41:44,044 - root - INFO - Step: 70 | Loss: 8.25 | Tokens per second: 7185.35 | Training tokens per second (%): 26.25 | MFU (%): 13.46 | TFLOPs: 133.09
2025-05-18 17:41:46,884 - root - INFO - Step: 75 | Loss: 8.34 | Tokens per second: 7264.83 | Training tokens per second (%): 16.89 | MFU (%): 13.61 | TFLOPs: 134.56
2025-05-18 17:41:49,725 - root - INFO - Step: 80 | Loss: 8.24 | Tokens per second: 7264.25 | Training tokens per second (%): 17.36 | MFU (%): 13.60 | TFLOPs: 134.55
2025-05-18 17:41:52,555 - root - INFO - Step: 85 | Loss: 8.34 | Tokens per second: 7289.69 | Training tokens per second (%): 16.04 | MFU (%): 13.65 | TFLOPs: 135.02
2025-05-18 17:41:55,558 - root - INFO - Step: 90 | Loss: 7.80 | Tokens per second: 6867.27 | Training tokens per second (%): 57.98 | MFU (%): 12.86 | TFLOPs: 127.20
2025-05-18 17:41:58,544 - root - INFO - Step: 95 | Loss: 7.53 | Tokens per second: 6907.61 | Training tokens per second (%): 57.90 | MFU (%): 12.94 | TFLOPs: 127.95
2025-05-18 17:42:01,655 - root - INFO - Step: 100 | Loss: 7.48 | Tokens per second: 6628.92 | Training tokens per second (%): 93.89 | MFU (%): 12.41 | TFLOPs: 122.78
2025-05-18 17:42:01,655 - root - INFO - Training completed
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 922, in <module>
    main()
  File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 918, in main
    run(args)
  File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 909, in run
    elastic_launch(
  File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    if result.is_failed():
       ^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'is_failed'
srun: error: nid006459: task 0: Exited with exit code 1
srun: Terminating StepId=447138.0
slurmstepd: error: *** STEP 447138.0 ON nid006459 CANCELLED AT 2025-05-18T17:42:04 ***
srun: error: nid006459: tasks 2-3: Terminated
srun: Force Terminated StepId=447138.0
END TIME: Sun May 18 17:42:05 CEST 2025
