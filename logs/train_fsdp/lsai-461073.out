START TIME: Fri May 23 19:35:52 CEST 2025
Node IP: 172.28.39.44
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
2025-05-23 19:36:14,292 - root - INFO - [RANK 0 / 16] Setting seed to 42
2025-05-23 19:36:14,292 - root - INFO - [RANK 0 / 16] AVAILABLE GPUS: 16
2025-05-23 19:36:14,292 - root - INFO - [RANK 0 / 16] NODES: 4.0
2025-05-23 19:36:14,292 - root - INFO - [RANK 0 / 16] Total RAM: 854.46 GB
2025-05-23 19:36:14,292 - root - INFO - [RANK 0 / 16] Available RAM: 775.82 GB
2025-05-23 19:36:14,292 - root - INFO - [RANK 0 / 16] Available per-process RAM: 193.96 GB
2025-05-23 19:36:20,881 - root - INFO - [RANK 0 / 16] GPU 0: NVIDIA GH200 120GB
2025-05-23 19:36:20,881 - root - INFO - [RANK 0 / 16]   Total memory: 94.50 GB
2025-05-23 19:36:20,881 - root - INFO - [RANK 0 / 16]   Allocated memory: 0.00 GB
2025-05-23 19:36:20,881 - root - INFO - [RANK 0 / 16]   Cached memory: 0.00 GB
2025-05-23 19:36:20,881 - root - INFO - [RANK 0 / 16] Experiment args: Namespace(dataset='/capstor/store/cscs/ethz/large-sc/datasets/train_data.parquet', tokenizer_name_or_path='unsloth/Mistral-Nemo-Base-2407-bnb-4bit', sequence_length=4096, batch_size=1, fused_optimizer=False, learning_rate=5e-05, lr_warmup_steps=100, training_steps=100, logging_frequency=5, profile=False, profile_step_start=10, profile_step_end=12, grad_max_norm=1, model_dtype='bf16', compile=False, scaling_factor=1, scaling_strategy=<ScalingStrategy.ALL: 'all'>, set_seed=42)
2025-05-23 19:36:20,881 - root - INFO - [RANK 0 / 16] world size: 16
2025-05-23 19:36:20,881 - root - INFO - [RANK 0 / 16] Setting up DataLoaders...
2025-05-23 19:36:24,051 - root - INFO - [RANK 0 / 16] Setting up Model...
2025-05-23 19:36:24,051 - root - INFO - [RANK 0 / 16] Loading a model with scale=1, scaling_strategy=ScalingStrategy.ALL, config:
TransformerModelArgs(dim=256, n_layers=8, n_heads=8, n_kv_heads=8, multiple_of=256, ffn_dim_multiplier=1.3, norm_eps=1e-05, rope_theta=500000, norm_type='rmsnorm', seq_len=4096, vocab_size=131072)
Total model parameters: 75501824
Total model parameters: 75501824
Total model parameters: 75501824
Total model parameters: 75501824
Total model parameters: 75501824
Total model parameters: 75501824
Total model parameters: 75501824
Total model parameters: 75501824
Total model parameters: 75501824
2025-05-23 19:36:24,704 - root - INFO - [RANK 0 / 16] Wrapping model with FSDP
Total model parameters: 75501824
Total model parameters:Total model parameters:  7550182475501824

Total model parameters: 75501824
Total model parameters: 75501824
Total model parameters: 75501824
Total model parameters: 75501824
2025-05-23 19:36:25,398 - root - INFO - [rank 12] local params: 4718864
2025-05-23 19:36:25,401 - root - INFO - [rank 14] local params: 4718864
2025-05-23 19:36:25,422 - root - INFO - [rank 6] local params: 4718864
2025-05-23 19:36:25,422 - root - INFO - [rank 7] local params: 4718864
2025-05-23 19:36:25,434 - root - INFO - [RANK 0 / 16] The model is now: FullyShardedDataParallel
2025-05-23 19:36:25,435 - root - INFO - [rank 0] local params: 4718864
2025-05-23 19:36:25,435 - root - INFO - [RANK 0 / 16] Starting training!
2025-05-23 19:36:25,436 - root - INFO - [rank 2] local params: 4718864
2025-05-23 19:36:25,438 - root - INFO - [rank 1] local params: 4718864
2025-05-23 19:36:25,438 - root - INFO - [rank 3] local params: 4718864
2025-05-23 19:36:25,440 - root - INFO - [rank 15] local params: 4718864
2025-05-23 19:36:25,440 - root - INFO - [rank 13] local params: 4718864
2025-05-23 19:36:25,447 - root - INFO - [rank 5] local params: 4718864
2025-05-23 19:36:25,460 - root - INFO - [rank 4] local params: 4718864
2025-05-23 19:36:25,507 - root - INFO - [rank 8] local params: 4718864
2025-05-23 19:36:25,509 - root - INFO - [rank 9] local params: 4718864
2025-05-23 19:36:25,509 - root - INFO - [rank 10] local params: 4718864
2025-05-23 19:36:25,509 - root - INFO - [rank 11] local params: 4718864
2025-05-23 19:36:31,568 - root - INFO - [RANK 0 / 16] Step: 1 | Loss: 11.99 | Tokens per second: 667.99 | Training tokens per second (%): 19.38 | MFU (%): 0.01 | TFLOPs: 0.09
2025-05-23 19:36:32,174 - root - INFO - [RANK 0 / 16] Step: 5 | Loss: 11.93 | Tokens per second: 27050.29 | Training tokens per second (%): 11.41 | MFU (%): 0.35 | TFLOPs: 3.49
2025-05-23 19:36:32,904 - root - INFO - [RANK 0 / 16] Step: 10 | Loss: 11.97 | Tokens per second: 28039.06 | Training tokens per second (%): 25.72 | MFU (%): 0.37 | TFLOPs: 3.62
2025-05-23 19:36:33,616 - root - INFO - [RANK 0 / 16] Step: 15 | Loss: 11.95 | Tokens per second: 28763.58 | Training tokens per second (%): 35.21 | MFU (%): 0.38 | TFLOPs: 3.71
2025-05-23 19:36:34,343 - root - INFO - [RANK 0 / 16] Step: 20 | Loss: 11.91 | Tokens per second: 28218.13 | Training tokens per second (%): 34.78 | MFU (%): 0.37 | TFLOPs: 3.64
2025-05-23 19:36:35,078 - root - INFO - [RANK 0 / 16] Step: 25 | Loss: 11.93 | Tokens per second: 27875.49 | Training tokens per second (%): 18.28 | MFU (%): 0.36 | TFLOPs: 3.60
2025-05-23 19:36:35,831 - root - INFO - [RANK 0 / 16] Step: 30 | Loss: 11.93 | Tokens per second: 27186.39 | Training tokens per second (%): 26.99 | MFU (%): 0.35 | TFLOPs: 3.51
2025-05-23 19:36:36,557 - root - INFO - [RANK 0 / 16] Step: 35 | Loss: 11.95 | Tokens per second: 28212.04 | Training tokens per second (%): 13.78 | MFU (%): 0.37 | TFLOPs: 3.64
2025-05-23 19:36:37,278 - root - INFO - [RANK 0 / 16] Step: 40 | Loss: 11.90 | Tokens per second: 28406.89 | Training tokens per second (%): 9.95 | MFU (%): 0.37 | TFLOPs: 3.66
2025-05-23 19:36:37,997 - root - INFO - [RANK 0 / 16] Step: 45 | Loss: 11.85 | Tokens per second: 28518.06 | Training tokens per second (%): 15.59 | MFU (%): 0.37 | TFLOPs: 3.68
2025-05-23 19:36:38,717 - root - INFO - [RANK 0 / 16] Step: 50 | Loss: 11.96 | Tokens per second: 28460.80 | Training tokens per second (%): 10.93 | MFU (%): 0.37 | TFLOPs: 3.67
2025-05-23 19:36:39,761 - root - INFO - [RANK 0 / 16] Step: 55 | Loss: 11.98 | Tokens per second: 19624.07 | Training tokens per second (%): 28.32 | MFU (%): 0.26 | TFLOPs: 2.53
2025-05-23 19:36:40,496 - root - INFO - [RANK 0 / 16] Step: 60 | Loss: 11.94 | Tokens per second: 27850.28 | Training tokens per second (%): 26.71 | MFU (%): 0.36 | TFLOPs: 3.59
2025-05-23 19:36:41,229 - root - INFO - [RANK 0 / 16] Step: 65 | Loss: 11.95 | Tokens per second: 27964.09 | Training tokens per second (%): 24.18 | MFU (%): 0.36 | TFLOPs: 3.61
2025-05-23 19:36:41,968 - root - INFO - [RANK 0 / 16] Step: 70 | Loss: 11.94 | Tokens per second: 27742.51 | Training tokens per second (%): 26.25 | MFU (%): 0.36 | TFLOPs: 3.58
2025-05-23 19:36:42,712 - root - INFO - [RANK 0 / 16] Step: 75 | Loss: 11.95 | Tokens per second: 27538.23 | Training tokens per second (%): 16.89 | MFU (%): 0.36 | TFLOPs: 3.55
2025-05-23 19:36:43,433 - root - INFO - [RANK 0 / 16] Step: 80 | Loss: 11.94 | Tokens per second: 28413.18 | Training tokens per second (%): 17.36 | MFU (%): 0.37 | TFLOPs: 3.66
2025-05-23 19:36:44,183 - root - INFO - [RANK 0 / 16] Step: 85 | Loss: 11.95 | Tokens per second: 27294.58 | Training tokens per second (%): 16.04 | MFU (%): 0.36 | TFLOPs: 3.52
2025-05-23 19:36:44,921 - root - INFO - [RANK 0 / 16] Step: 90 | Loss: 11.89 | Tokens per second: 27770.52 | Training tokens per second (%): 57.98 | MFU (%): 0.36 | TFLOPs: 3.58
2025-05-23 19:36:45,639 - root - INFO - [RANK 0 / 16] Step: 95 | Loss: 11.84 | Tokens per second: 28533.75 | Training tokens per second (%): 57.90 | MFU (%): 0.37 | TFLOPs: 3.68
2025-05-23 19:36:46,403 - root - INFO - [RANK 0 / 16] Step: 100 | Loss: 11.84 | Tokens per second: 26816.36 | Training tokens per second (%): 93.89 | MFU (%): 0.35 | TFLOPs: 3.46
2025-05-23 19:36:46,404 - root - INFO - [RANK 0 / 16] Training completed
2025-05-23 19:36:46,404 - root - INFO - [RANK 0 / 16] Took 0 min 25 sec
END TIME: Fri May 23 19:36:51 CEST 2025
