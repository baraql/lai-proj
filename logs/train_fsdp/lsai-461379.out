START TIME: Fri May 23 23:20:17 CEST 2025
Node IP: 172.28.31.232
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
2025-05-23 23:20:41,345 - root - INFO - [RANK 0 / 2] Setting seed to 42
2025-05-23 23:20:41,345 - root - INFO - [RANK 0 / 2] AVAILABLE GPUS: 2
2025-05-23 23:20:41,345 - root - INFO - [RANK 0 / 2] NODES: 2.0
2025-05-23 23:20:41,346 - root - INFO - [RANK 0 / 2] Total RAM: 854.46 GB
2025-05-23 23:20:41,346 - root - INFO - [RANK 0 / 2] Available RAM: 777.39 GB
2025-05-23 23:20:41,346 - root - INFO - [RANK 0 / 2] Available per-process RAM: 777.39 GB
2025-05-23 23:20:42,591 - root - INFO - [RANK 0 / 2] GPU 0: NVIDIA GH200 120GB
2025-05-23 23:20:42,592 - root - INFO - [RANK 0 / 2]   Total memory: 94.50 GB
2025-05-23 23:20:42,592 - root - INFO - [RANK 0 / 2]   Allocated memory: 0.00 GB
2025-05-23 23:20:42,592 - root - INFO - [RANK 0 / 2]   Cached memory: 0.00 GB
2025-05-23 23:20:42,592 - root - INFO - [RANK 0 / 2] Experiment args: Namespace(dataset='/capstor/store/cscs/ethz/large-sc/datasets/train_data.parquet', tokenizer_name_or_path='unsloth/Mistral-Nemo-Base-2407-bnb-4bit', sequence_length=4096, batch_size=1, fused_optimizer=False, learning_rate=5e-05, lr_warmup_steps=100, training_steps=100, logging_frequency=5, profile=False, profile_step_start=10, profile_step_end=12, grad_max_norm=1, model_dtype='bf16', compile=False, scaling_factor=2, scaling_strategy=<ScalingStrategy.ALL: 'all'>, set_seed=42)
2025-05-23 23:20:42,592 - root - INFO - [RANK 0 / 2] world size: 2
2025-05-23 23:20:42,592 - root - INFO - [RANK 0 / 2] Setting up DataLoaders...
2025-05-23 23:20:46,454 - root - INFO - [RANK 0 / 2] Setting up Model...
2025-05-23 23:20:46,455 - root - INFO - [RANK 0 / 2] Loading a model with scale=2, scaling_strategy=ScalingStrategy.ALL, config:
TransformerModelArgs(dim=512, n_layers=16, n_heads=16, n_kv_heads=8, multiple_of=256, ffn_dim_multiplier=1.3, norm_eps=1e-05, rope_theta=500000, norm_type='rmsnorm', seq_len=4096, vocab_size=131072)
Total model parameters: 190857728
Total model parameters: 190857728
2025-05-23 23:20:47,819 - root - INFO - [RANK 0 / 2] Wrapping model with FSDP
2025-05-23 23:20:48,076 - root - INFO - [RANK 0 / 2] The model is now: FullyShardedDataParallel
2025-05-23 23:20:48,076 - root - INFO - [rank 0] local params: 95428864
2025-05-23 23:20:48,077 - root - INFO - [RANK 0 / 2] Starting training!
2025-05-23 23:20:48,118 - root - INFO - [rank 1] local params: 95428864
2025-05-23 23:20:51,000 - root - INFO - [RANK 0 / 2] Step: 1 | Loss: 11.92 | Tokens per second: 1401.92 | Training tokens per second (%): 19.38 | MFU (%): 0.14 | TFLOPs: 1.37
2025-05-23 23:20:51,476 - root - INFO - [RANK 0 / 2] Step: 5 | Loss: 11.95 | Tokens per second: 34410.88 | Training tokens per second (%): 11.41 | MFU (%): 3.39 | TFLOPs: 33.56
2025-05-23 23:20:52,069 - root - INFO - [RANK 0 / 2] Step: 10 | Loss: 11.93 | Tokens per second: 34586.82 | Training tokens per second (%): 25.72 | MFU (%): 3.41 | TFLOPs: 33.73
2025-05-23 23:20:52,661 - root - INFO - [RANK 0 / 2] Step: 15 | Loss: 11.96 | Tokens per second: 34626.48 | Training tokens per second (%): 35.21 | MFU (%): 3.41 | TFLOPs: 33.77
2025-05-23 23:20:53,258 - root - INFO - [RANK 0 / 2] Step: 20 | Loss: 11.91 | Tokens per second: 34321.30 | Training tokens per second (%): 34.78 | MFU (%): 3.38 | TFLOPs: 33.47
2025-05-23 23:20:53,855 - root - INFO - [RANK 0 / 2] Step: 25 | Loss: 11.90 | Tokens per second: 34342.61 | Training tokens per second (%): 18.28 | MFU (%): 3.39 | TFLOPs: 33.49
2025-05-23 23:20:54,610 - root - INFO - [RANK 0 / 2] Step: 30 | Loss: 11.93 | Tokens per second: 27129.85 | Training tokens per second (%): 26.99 | MFU (%): 2.68 | TFLOPs: 26.46
2025-05-23 23:20:55,202 - root - INFO - [RANK 0 / 2] Step: 35 | Loss: 11.97 | Tokens per second: 34634.67 | Training tokens per second (%): 13.78 | MFU (%): 3.42 | TFLOPs: 33.78
2025-05-23 23:20:55,787 - root - INFO - [RANK 0 / 2] Step: 40 | Loss: 11.94 | Tokens per second: 35024.87 | Training tokens per second (%): 9.95 | MFU (%): 3.45 | TFLOPs: 34.16
2025-05-23 23:20:56,377 - root - INFO - [RANK 0 / 2] Step: 45 | Loss: 11.95 | Tokens per second: 34708.29 | Training tokens per second (%): 15.59 | MFU (%): 3.42 | TFLOPs: 33.85
2025-05-23 23:20:56,967 - root - INFO - [RANK 0 / 2] Step: 50 | Loss: 11.87 | Tokens per second: 34778.99 | Training tokens per second (%): 10.93 | MFU (%): 3.43 | TFLOPs: 33.92
2025-05-23 23:20:57,555 - root - INFO - [RANK 0 / 2] Step: 55 | Loss: 11.82 | Tokens per second: 34862.01 | Training tokens per second (%): 28.32 | MFU (%): 3.44 | TFLOPs: 34.00
2025-05-23 23:20:58,147 - root - INFO - [RANK 0 / 2] Step: 60 | Loss: 11.87 | Tokens per second: 34571.10 | Training tokens per second (%): 26.71 | MFU (%): 3.41 | TFLOPs: 33.71
2025-05-23 23:20:58,739 - root - INFO - [RANK 0 / 2] Step: 65 | Loss: 11.85 | Tokens per second: 34661.52 | Training tokens per second (%): 24.18 | MFU (%): 3.42 | TFLOPs: 33.80
2025-05-23 23:20:59,334 - root - INFO - [RANK 0 / 2] Step: 70 | Loss: 11.79 | Tokens per second: 34422.61 | Training tokens per second (%): 26.25 | MFU (%): 3.39 | TFLOPs: 33.57
2025-05-23 23:20:59,924 - root - INFO - [RANK 0 / 2] Step: 75 | Loss: 11.70 | Tokens per second: 34774.95 | Training tokens per second (%): 16.89 | MFU (%): 3.43 | TFLOPs: 33.91
2025-05-23 23:21:00,512 - root - INFO - [RANK 0 / 2] Step: 80 | Loss: 11.58 | Tokens per second: 34817.47 | Training tokens per second (%): 17.36 | MFU (%): 3.43 | TFLOPs: 33.95
2025-05-23 23:21:01,108 - root - INFO - [RANK 0 / 2] Step: 85 | Loss: 11.57 | Tokens per second: 34390.01 | Training tokens per second (%): 16.04 | MFU (%): 3.39 | TFLOPs: 33.54
2025-05-23 23:21:01,717 - root - INFO - [RANK 0 / 2] Step: 90 | Loss: 11.35 | Tokens per second: 33679.64 | Training tokens per second (%): 57.98 | MFU (%): 3.32 | TFLOPs: 32.85
2025-05-23 23:21:02,339 - root - INFO - [RANK 0 / 2] Step: 95 | Loss: 11.09 | Tokens per second: 32911.03 | Training tokens per second (%): 57.90 | MFU (%): 3.25 | TFLOPs: 32.10
2025-05-23 23:21:02,971 - root - INFO - [RANK 0 / 2] Step: 100 | Loss: 10.85 | Tokens per second: 32465.00 | Training tokens per second (%): 93.89 | MFU (%): 3.20 | TFLOPs: 31.66
2025-05-23 23:21:02,971 - root - INFO - [RANK 0 / 2] Training completed
2025-05-23 23:21:02,971 - root - INFO - [RANK 0 / 2] Took 0 min 20 sec
END TIME: Fri May 23 23:21:05 CEST 2025
