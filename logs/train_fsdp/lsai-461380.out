START TIME: Fri May 23 23:21:34 CEST 2025
Node IP: 172.28.31.232
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
2025-05-23 23:21:55,775 - root - INFO - [RANK 0 / 2] Setting seed to 42
2025-05-23 23:21:55,775 - root - INFO - [RANK 0 / 2] AVAILABLE GPUS: 2
2025-05-23 23:21:55,775 - root - INFO - [RANK 0 / 2] NODES: 2.0
2025-05-23 23:21:55,775 - root - INFO - [RANK 0 / 2] Total RAM: 854.46 GB
2025-05-23 23:21:55,775 - root - INFO - [RANK 0 / 2] Available RAM: 778.05 GB
2025-05-23 23:21:55,775 - root - INFO - [RANK 0 / 2] Available per-process RAM: 778.05 GB
2025-05-23 23:21:56,964 - root - INFO - [RANK 0 / 2] GPU 0: NVIDIA GH200 120GB
2025-05-23 23:21:56,965 - root - INFO - [RANK 0 / 2]   Total memory: 94.50 GB
2025-05-23 23:21:56,965 - root - INFO - [RANK 0 / 2]   Allocated memory: 0.00 GB
2025-05-23 23:21:56,965 - root - INFO - [RANK 0 / 2]   Cached memory: 0.00 GB
2025-05-23 23:21:56,965 - root - INFO - [RANK 0 / 2] Experiment args: Namespace(dataset='/capstor/store/cscs/ethz/large-sc/datasets/train_data.parquet', tokenizer_name_or_path='unsloth/Mistral-Nemo-Base-2407-bnb-4bit', sequence_length=4096, batch_size=1, fused_optimizer=False, learning_rate=5e-05, lr_warmup_steps=100, training_steps=100, logging_frequency=5, profile=False, profile_step_start=10, profile_step_end=12, grad_max_norm=1, model_dtype='bf16', compile=False, scaling_factor=4, scaling_strategy=<ScalingStrategy.ALL: 'all'>, set_seed=42)
2025-05-23 23:21:56,965 - root - INFO - [RANK 0 / 2] world size: 2
2025-05-23 23:21:56,965 - root - INFO - [RANK 0 / 2] Setting up DataLoaders...
2025-05-23 23:22:00,464 - root - INFO - [RANK 0 / 2] Setting up Model...
2025-05-23 23:22:00,464 - root - INFO - [RANK 0 / 2] Loading a model with scale=4, scaling_strategy=ScalingStrategy.ALL, config:
TransformerModelArgs(dim=1024, n_layers=32, n_heads=32, n_kv_heads=8, multiple_of=256, ffn_dim_multiplier=1.3, norm_eps=1e-05, rope_theta=500000, norm_type='rmsnorm', seq_len=4096, vocab_size=131072)
Total model parameters: 704709632
2025-05-23 23:22:04,301 - root - INFO - [RANK 0 / 2] Wrapping model with FSDP
Total model parameters: 704709632
2025-05-23 23:22:04,619 - root - INFO - [RANK 0 / 2] The model is now: FullyShardedDataParallel
2025-05-23 23:22:04,620 - root - INFO - [rank 0] local params: 352354816
2025-05-23 23:22:04,621 - root - INFO - [RANK 0 / 2] Starting training!
2025-05-23 23:22:04,671 - root - INFO - [rank 1] local params: 352354816
2025-05-23 23:22:07,711 - root - INFO - [RANK 0 / 2] Step: 1 | Loss: 11.98 | Tokens per second: 1325.92 | Training tokens per second (%): 19.38 | MFU (%): 0.50 | TFLOPs: 4.94
2025-05-23 23:22:09,029 - root - INFO - [RANK 0 / 2] Step: 5 | Loss: 11.94 | Tokens per second: 12441.22 | Training tokens per second (%): 11.41 | MFU (%): 4.69 | TFLOPs: 46.34
2025-05-23 23:22:10,427 - root - INFO - [RANK 0 / 2] Step: 10 | Loss: 11.91 | Tokens per second: 14648.37 | Training tokens per second (%): 25.72 | MFU (%): 5.52 | TFLOPs: 54.56
2025-05-23 23:22:11,852 - root - INFO - [RANK 0 / 2] Step: 15 | Loss: 11.93 | Tokens per second: 14382.18 | Training tokens per second (%): 35.21 | MFU (%): 5.42 | TFLOPs: 53.57
2025-05-23 23:22:13,270 - root - INFO - [RANK 0 / 2] Step: 20 | Loss: 11.87 | Tokens per second: 14449.47 | Training tokens per second (%): 34.78 | MFU (%): 5.44 | TFLOPs: 53.82
2025-05-23 23:22:14,672 - root - INFO - [RANK 0 / 2] Step: 25 | Loss: 11.87 | Tokens per second: 14613.23 | Training tokens per second (%): 18.28 | MFU (%): 5.50 | TFLOPs: 54.43
2025-05-23 23:22:16,081 - root - INFO - [RANK 0 / 2] Step: 30 | Loss: 11.78 | Tokens per second: 14541.63 | Training tokens per second (%): 26.99 | MFU (%): 5.48 | TFLOPs: 54.16
2025-05-23 23:22:17,486 - root - INFO - [RANK 0 / 2] Step: 35 | Loss: 11.69 | Tokens per second: 14573.93 | Training tokens per second (%): 13.78 | MFU (%): 5.49 | TFLOPs: 54.28
2025-05-23 23:22:18,881 - root - INFO - [RANK 0 / 2] Step: 40 | Loss: 11.63 | Tokens per second: 14686.07 | Training tokens per second (%): 9.95 | MFU (%): 5.53 | TFLOPs: 54.70
2025-05-23 23:22:20,333 - root - INFO - [RANK 0 / 2] Step: 45 | Loss: 11.26 | Tokens per second: 14111.79 | Training tokens per second (%): 15.59 | MFU (%): 5.31 | TFLOPs: 52.56
2025-05-23 23:22:21,723 - root - INFO - [RANK 0 / 2] Step: 50 | Loss: 11.15 | Tokens per second: 14744.38 | Training tokens per second (%): 10.93 | MFU (%): 5.55 | TFLOPs: 54.92
2025-05-23 23:22:23,137 - root - INFO - [RANK 0 / 2] Step: 55 | Loss: 11.34 | Tokens per second: 14482.08 | Training tokens per second (%): 28.32 | MFU (%): 5.45 | TFLOPs: 53.94
2025-05-23 23:22:24,530 - root - INFO - [RANK 0 / 2] Step: 60 | Loss: 10.84 | Tokens per second: 14710.13 | Training tokens per second (%): 26.71 | MFU (%): 5.54 | TFLOPs: 54.79
2025-05-23 23:22:25,933 - root - INFO - [RANK 0 / 2] Step: 65 | Loss: 10.88 | Tokens per second: 14601.03 | Training tokens per second (%): 24.18 | MFU (%): 5.50 | TFLOPs: 54.39
2025-05-23 23:22:27,343 - root - INFO - [RANK 0 / 2] Step: 70 | Loss: 10.62 | Tokens per second: 14529.62 | Training tokens per second (%): 26.25 | MFU (%): 5.47 | TFLOPs: 54.12
2025-05-23 23:22:28,750 - root - INFO - [RANK 0 / 2] Step: 75 | Loss: 10.08 | Tokens per second: 14557.31 | Training tokens per second (%): 16.89 | MFU (%): 5.48 | TFLOPs: 54.22
2025-05-23 23:22:30,289 - root - INFO - [RANK 0 / 2] Step: 80 | Loss: 10.09 | Tokens per second: 13312.89 | Training tokens per second (%): 17.36 | MFU (%): 5.01 | TFLOPs: 49.59
2025-05-23 23:22:31,695 - root - INFO - [RANK 0 / 2] Step: 85 | Loss: 10.17 | Tokens per second: 14575.31 | Training tokens per second (%): 16.04 | MFU (%): 5.49 | TFLOPs: 54.29
2025-05-23 23:22:33,131 - root - INFO - [RANK 0 / 2] Step: 90 | Loss: 9.79 | Tokens per second: 14266.52 | Training tokens per second (%): 57.98 | MFU (%): 5.37 | TFLOPs: 53.14
2025-05-23 23:22:34,584 - root - INFO - [RANK 0 / 2] Step: 95 | Loss: 9.55 | Tokens per second: 14096.53 | Training tokens per second (%): 57.90 | MFU (%): 5.31 | TFLOPs: 52.51
2025-05-23 23:22:36,067 - root - INFO - [RANK 0 / 2] Step: 100 | Loss: 9.28 | Tokens per second: 13815.01 | Training tokens per second (%): 93.89 | MFU (%): 5.20 | TFLOPs: 51.46
2025-05-23 23:22:36,067 - root - INFO - [RANK 0 / 2] Training completed
2025-05-23 23:22:36,067 - root - INFO - [RANK 0 / 2] Took 0 min 39 sec
END TIME: Fri May 23 23:22:38 CEST 2025
