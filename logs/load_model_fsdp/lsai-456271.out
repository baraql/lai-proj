START TIME: Thu May 22 00:00:17 CEST 2025
Node IP: 172.28.39.124
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
2025-05-22 00:00:40,472 - root - INFO - Loading a model with scale=10, scaling_strategy=ScalingStrategy.ALL, config:
TransformerModelArgs(dim=2560, n_layers=80, n_heads=80, n_kv_heads=8, multiple_of=256, ffn_dim_multiplier=1.3, norm_eps=1e-05, rope_theta=500000, norm_type='rmsnorm', seq_len=4096, vocab_size=131072)
2025-05-22 00:00:40,472 - root - INFO - Loading a model with scale=10, scaling_strategy=ScalingStrategy.ALL, config:
TransformerModelArgs(dim=2560, n_layers=80, n_heads=80, n_kv_heads=8, multiple_of=256, ffn_dim_multiplier=1.3, norm_eps=1e-05, rope_theta=500000, norm_type='rmsnorm', seq_len=4096, vocab_size=131072)
2025-05-22 00:00:40,472 - root - INFO - Loading a model with scale=10, scaling_strategy=ScalingStrategy.ALL, config:
TransformerModelArgs(dim=2560, n_layers=80, n_heads=80, n_kv_heads=8, multiple_of=256, ffn_dim_multiplier=1.3, norm_eps=1e-05, rope_theta=500000, norm_type='rmsnorm', seq_len=4096, vocab_size=131072)
2025-05-22 00:00:40,484 - root - INFO - Loading a model with scale=10, scaling_strategy=ScalingStrategy.ALL, config:
TransformerModelArgs(dim=2560, n_layers=80, n_heads=80, n_kv_heads=8, multiple_of=256, ffn_dim_multiplier=1.3, norm_eps=1e-05, rope_theta=500000, norm_type='rmsnorm', seq_len=4096, vocab_size=131072)
2025-05-22 00:00:40,486 - root - INFO - Loading a model with scale=10, scaling_strategy=ScalingStrategy.ALL, config:
TransformerModelArgs(dim=2560, n_layers=80, n_heads=80, n_kv_heads=8, multiple_of=256, ffn_dim_multiplier=1.3, norm_eps=1e-05, rope_theta=500000, norm_type='rmsnorm', seq_len=4096, vocab_size=131072)
2025-05-22 00:00:40,487 - root - INFO - Loading a model with scale=10, scaling_strategy=ScalingStrategy.ALL, config:
TransformerModelArgs(dim=2560, n_layers=80, n_heads=80, n_kv_heads=8, multiple_of=256, ffn_dim_multiplier=1.3, norm_eps=1e-05, rope_theta=500000, norm_type='rmsnorm', seq_len=4096, vocab_size=131072)
2025-05-22 00:00:40,594 - root - INFO - Loading a model with scale=10, scaling_strategy=ScalingStrategy.ALL, config:
TransformerModelArgs(dim=2560, n_layers=80, n_heads=80, n_kv_heads=8, multiple_of=256, ffn_dim_multiplier=1.3, norm_eps=1e-05, rope_theta=500000, norm_type='rmsnorm', seq_len=4096, vocab_size=131072)
2025-05-22 00:00:40,646 - root - INFO - Loading a model with scale=10, scaling_strategy=ScalingStrategy.ALL, config:
TransformerModelArgs(dim=2560, n_layers=80, n_heads=80, n_kv_heads=8, multiple_of=256, ffn_dim_multiplier=1.3, norm_eps=1e-05, rope_theta=500000, norm_type='rmsnorm', seq_len=4096, vocab_size=131072)
2025-05-22 00:01:09,438 - root - INFO - Total model parameters: 7,329,958,400
2025-05-22 00:01:09,466 - root - INFO - Total model parameters: 7,329,958,400
2025-05-22 00:01:09,510 - root - INFO - Total model parameters: 7,329,958,400
2025-05-22 00:01:09,520 - root - INFO - Total model parameters: 7,329,958,400
2025-05-22 00:01:09,662 - root - INFO - Total model parameters: 7,329,958,400
2025-05-22 00:01:09,664 - root - INFO - Total model parameters: 7,329,958,400
2025-05-22 00:01:10,646 - root - INFO - Total model parameters: 7,329,958,400
2025-05-22 00:01:10,882 - root - INFO - Total model parameters: 7,329,958,400
2025-05-22 00:01:16,320 - root - INFO - [rank 0]Took 0 min 36 sec
2025-05-22 00:01:16,320 - root - INFO - [rank 0]


END TIME: Thu May 22 00:01:19 CEST 2025
