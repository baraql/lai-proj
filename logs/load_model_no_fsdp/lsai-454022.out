START TIME: Tue May 20 23:42:24 CEST 2025
Running /iopsstor/scratch/cscs/elyulina/lai-proj/load_model_no_fsdp.py
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
2025-05-20 23:42:46,394 - root - INFO - Starting the main function
2025-05-20 23:42:46,394 - root - INFO - Running binary search with scale low=15, high=30, precision=0, scaling_strategy=ScalingStrategy.N_LAYERS
2025-05-20 23:42:56,771 - root - INFO - Loading a model with scale=22, scaling_strategy=ScalingStrategy.N_LAYERS, config:
TransformerModelArgs(dim=4096, n_layers=704, n_heads=32, n_kv_heads=8, multiple_of=1024, ffn_dim_multiplier=1.3, norm_eps=1e-05, rope_theta=500000, norm_type='rmsnorm', seq_len=4096, vocab_size=131072)
2025-05-20 23:52:18,517 - root - INFO - Error while loading the model!
2025-05-20 23:52:18,517 - root - INFO - CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacity of 94.50 GiB of which 2.62 GiB is free. Including non-PyTorch memory, this process has 91.67 GiB memory in use. Of the allocated memory 90.27 GiB is allocated by PyTorch, and 880.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-05-20 23:52:19,527 - root - INFO - Took 9 min 33 sec
2025-05-20 23:52:19,528 - root - INFO - 


2025-05-20 23:52:20,445 - root - INFO - Loading a model with scale=18, scaling_strategy=ScalingStrategy.N_LAYERS, config:
TransformerModelArgs(dim=4096, n_layers=576, n_heads=32, n_kv_heads=8, multiple_of=1024, ffn_dim_multiplier=1.3, norm_eps=1e-05, rope_theta=500000, norm_type='rmsnorm', seq_len=4096, vocab_size=131072)
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 454022.0 ON nid006674 CANCELLED AT 2025-05-20T23:53:34 ***
slurmstepd: error: *** JOB 454022 ON nid006674 CANCELLED AT 2025-05-20T23:53:34 ***
srun: forcing job termination
srun: got SIGCONT
