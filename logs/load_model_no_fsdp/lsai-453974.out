START TIME: Tue May 20 23:18:46 CEST 2025
Running /iopsstor/scratch/cscs/elyulina/lai-proj/load_model_no_fsdp.py
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
2025-05-20 23:19:12,945 - root - INFO - Starting the main function
2025-05-20 23:19:12,945 - root - INFO - Running binary search with scale low=1, high=17, precision=0, scale only n_layers=False
2025-05-20 23:19:13,463 - root - INFO - Loading a model with scale=9, scaling_strategy=ScalingStrategy.ALL, config:
TransformerModelArgs(dim=2304, n_layers=36, n_heads=36, n_kv_heads=8, multiple_of=256, ffn_dim_multiplier=1.3, norm_eps=1e-05, rope_theta=500000, norm_type='rmsnorm', seq_len=4096, vocab_size=131072)
2025-05-20 23:19:29,239 - root - INFO - Actual model parameters: 3,109,720,320
2025-05-20 23:19:29,239 - root - INFO - Took 0 min 16 sec
2025-05-20 23:19:29,239 - root - INFO - 


2025-05-20 23:19:29,913 - root - INFO - Loading a model with scale=13, scaling_strategy=ScalingStrategy.ALL, config:
TransformerModelArgs(dim=3328, n_layers=52, n_heads=52, n_kv_heads=8, multiple_of=256, ffn_dim_multiplier=1.3, norm_eps=1e-05, rope_theta=500000, norm_type='rmsnorm', seq_len=4096, vocab_size=131072)
2025-05-20 23:20:04,660 - root - INFO - Actual model parameters: 8,315,557,120
2025-05-20 23:20:04,661 - root - INFO - Took 0 min 35 sec
2025-05-20 23:20:04,661 - root - INFO - 


2025-05-20 23:20:05,317 - root - INFO - Loading a model with scale=15, scaling_strategy=ScalingStrategy.ALL, config:
TransformerModelArgs(dim=3840, n_layers=60, n_heads=60, n_kv_heads=8, multiple_of=256, ffn_dim_multiplier=1.3, norm_eps=1e-05, rope_theta=500000, norm_type='rmsnorm', seq_len=4096, vocab_size=131072)
2025-05-20 23:20:54,894 - root - INFO - Actual model parameters: 12,213,753,600
2025-05-20 23:20:54,895 - root - INFO - Took 0 min 50 sec
2025-05-20 23:20:54,895 - root - INFO - 


2025-05-20 23:20:55,571 - root - INFO - Loading a model with scale=16, scaling_strategy=ScalingStrategy.ALL, config:
TransformerModelArgs(dim=4096, n_layers=64, n_heads=64, n_kv_heads=8, multiple_of=256, ffn_dim_multiplier=1.3, norm_eps=1e-05, rope_theta=500000, norm_type='rmsnorm', seq_len=4096, vocab_size=131072)
2025-05-20 23:21:55,167 - root - INFO - Actual model parameters: 14,764,478,464
2025-05-20 23:21:55,167 - root - INFO - Took 1 min 0 sec
2025-05-20 23:21:55,167 - root - INFO - 


2025-05-20 23:21:55,855 - root - INFO - Loading a model with scale=17, scaling_strategy=ScalingStrategy.ALL, config:
TransformerModelArgs(dim=4352, n_layers=68, n_heads=68, n_kv_heads=8, multiple_of=256, ffn_dim_multiplier=1.3, norm_eps=1e-05, rope_theta=500000, norm_type='rmsnorm', seq_len=4096, vocab_size=131072)
2025-05-20 23:23:05,684 - root - INFO - Actual model parameters: 17,429,764,352
2025-05-20 23:23:05,685 - root - INFO - Took 1 min 10 sec
2025-05-20 23:23:05,685 - root - INFO - 


2025-05-20 23:23:05,908 - root - INFO - Best fit: 17
Traceback (most recent call last):
  File "/iopsstor/scratch/cscs/elyulina/lai-proj/load_model_no_fsdp.py", line 125, in <module>
    load_model_no_fsdp(saling_factor=best_fit, scaling_strategy=scaling_strategy)
TypeError: load_model_no_fsdp() got an unexpected keyword argument 'saling_factor'
srun: error: nid006841: task 0: Exited with exit code 1
srun: Terminating StepId=453974.0
